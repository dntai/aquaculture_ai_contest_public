<!--
Slides:
adler-team_aqua21_challenge_results_korver.pptx
+ https://ejnu-my.sharepoint.com/:p:/g/personal/176680_jnu_ac_kr/EZCIMDaTsjhGiomCQ2cuVJkBxpNuIb2yzgNIAVlDXezKWg?e=168lWw
adler_a2i_presentation.pptx
+ https://ejnu-my.sharepoint.com/:p:/g/personal/176680_jnu_ac_kr/Edm6HmX88L1OlLL3AnAjAfoB7CUI-1MTSCy4cKn-IR87kQ?e=c461ad

https://ejnu-my.sharepoint.com/:b:/g/personal/176680_jnu_ac_kr/EVu-1YCVsfxArJ5tDdmo4ucBz2xBxtaSTH_x7j9d29KQ1Q?e=No7hgS
-->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>2021 Aquaculture Artificial Intelligence Idea Contest</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- TITLE -->
    <center>
        <span style="font-size:36px">2021 Aquaculture Artificial Intelligence Idea Contest</span>
        <table align=center width=600px>
            <tr>
	  	        <td align=center width=100px>
	  			    <center>
	  				    <span style="font-size:28px">ADLER Team<small><sup>1</sup></small></span><br/>
                        <small><sup>1</sup>Aquaculture Deep Learning Enhanced Research Team</small><br/>
	  					<span style="font-size:22px">Chonnam National University</span><br>
                    </center>
                </td>
            </tr>
        </table>

        <!-- LINKS -->
        <table align=center width=600px>
            <tr>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='./resources/docs/2112_aqua21_smart_aquaculture_deep_learning.pdf'>[Paper]</a></span></br>
                        <span style="font-size:18px">(English)</span>
                        <!-- <span style="font-size:24px"><a href='https://arxiv.org/abs/...'>[Paper]</a></span> -->
                    </center>
                </td>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='./resources/docs/2112_aqua21_smart_aquaculture_deep_learning_korver.pdf'>[Paper]</a></span></br>
                        <span style="font-size:18px">(Korean)</span>
                        <!-- <span style="font-size:24px"><a href='https://arxiv.org/abs/...'>[Paper]</a></span> -->
                    </center>
                </td>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='https://github.com/dntai/aquaculture_ai_contest_public'>[GitHub]</a></span><br>
                        <span style="font-size:18px">&nbsp;</span>
                    </center>
                </td>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='https://www.youtube.com/watch?v=T529Nq_P3qc'>[Talk]</a></span><br>
                        <!-- Under construction -->
                        <span style="font-size:18px">&nbsp;</span>
                    </center>
                </td>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='https://youtu.be/Vs9v_EXVCn0'>[Demo]</a></span><br>
                        <span style="font-size:18px">&nbsp;</span>
                        <!-- <span style="font-size:18px"> Under construction</span> -->
                    </center>
                </td>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='https://ejnu-my.sharepoint.com/:p:/g/personal/176680_jnu_ac_kr/Edm6HmX88L1OlLL3AnAjAfoB7CUI-1MTSCy4cKn-IR87kQ?e=c461ad'>[Slides]</a></span><br>
                        <span style="font-size:18px">(English)</span>
                        <!-- <span style="font-size:18px">127 MB</span> -->
                    </center>
                </td>
                <td align=center width=120px>
                    <center>
                        <span style="font-size:24px"><a href='https://ejnu-my.sharepoint.com/:p:/g/personal/176680_jnu_ac_kr/EZCIMDaTsjhGiomCQ2cuVJkBxpNuIb2yzgNIAVlDXezKWg?e=168lWw'>[Slides]</a></span><br>
                        <span style="font-size:18px">(Korean)</span>
                        <!-- <span style="font-size:18px">127 MB</span> -->
                    </center>
                </td>
            </tr>
        </table>
    </center>

    <!-- Introduction -->
    <center>
        <h1>Introduction</h1>
        <table align=center class="fixed">
            <tr>
              <td>
                  <p><b>Overview</b></p>
                  <p class="justify-align">
                      In the 4th industrial revolution, smart aquaculture has become a hot issue as an alternative to nurture and develop the fishery industry. It helps in remotely and automatically managing aquaculture breeding and growth environment to improve aquaculture health care.
                  </p>
                  <p class="justify-align">
                      Core technology development is required to build an open platform for collecting and sharing big data on aquaculture sites such as fish growth and disease information, environmental data. Besides, it needs to create an intelligent hub platform for the aquaculture industry.
                      An intelligent platform-based IoT ecosystem in a smart aquaculture system consists of an IoT system for remotely and automatically management (automatic feed device, water quality sensors, camera), the portal hub for collecting and sharing data on aquaculture sites, software for monitoring and intelligent core applied Artificial intelligent for making the decision.
                  </p>
                  <figure align="center">
                    <img class="round" style="height:250px" src="./resources/smart_aquaculture_system.png"/>
                      <figcaption>
                          Smart Aquaculture System Concept<sup>1</sup>.<br/>
                          <small><sup>1</sup>T. T. E. Vo, H. Ko, J. Huh, and Y. Kim, “Overview of Smart Aquaculture System: Focusing on Applications of Machine Learning and Computer Vision,” Electronics, vol. 10, no. 22, p. 2882, Nov. 2021
</small>
                      </figcaption>
                  </figure>
                  <p><b>Motivation</b></p>

                  <p class="justify-align">
                      Stable mass feeding management of food organisms is a significant problem in the aquaculture industry. However, the aquaculture artificial seed production industry has many issues that cause severe economic loss. They consist of reducing aquaculture food organisms, difficulties in managing mass feeding of food organisms, mass mortality in seed production, and decreasing utilization of food organisms by field.
                  </p>
                  <p class="justify-align">
                      In this challenging contest, we focus on proposing an artificial intelligence method and a system prototype to tackle fundamental problems such as instability and low productivity in the artificial seed culture industry.
                  </p>
              </td>
            </tr>
        </table>
    </center>

    <!-- Proposed System -->
    <center>
        <h1>Proposed method</h1>
        <table align=center class="fixed">
            <tr>
                <td>
                    <p><b>Problem Definition</b></p>
                    <p class="justify-align">
                        We assess the water quality corresponding with microscopy results of cell counting of food organisms. The input sensor data comprised of Temperature, Dissolved oxygen (DO), pH, salinity, and Turbidity(NTU).
                        The system returns the cell density given by microscopy images.
                        From there, we can control the water quality suitable for seed development.
                    </p>
                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/problem_definition.png"/>
                          <figcaption>Problem Definition</figcaption>
                    </figure>

                    <p class="justify-align">
                        We use computer vision techniques (Otsu morphology and Blob Detection) to return cell density given by microscopy images.
                    </p>
                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/cell_detection.png"/>
                          <figcaption>Cell Detection</figcaption>
                    </figure>

                    <p><b>Network Architecture</b></p>
                    <p class="justify-align">
                        Our model exploits the feature selection of five quality parameters based on deep learning techniques (transformer, table mask for feature selection, and Auto-Encoder architecture)
                    </p>
                    <figure align="center">
                        <img class="round" src="./resources/model_architecture.png"/>
                        <figcaption>Our Model Architecture</figcaption>
                    </figure>
                </td>
            </tr>
        </table>
    </center>

    <!-- Prototype System -->
    <center>
        <h1>Prototype System</h1>
        <table align=center class="fixed">
            <tr>
                <td>
                    <p><b>Development Environment</b></p>
                    <p class="justify-align">
                        We develop our prototype system using the webpage serverside supporting bootstrap and python. The main reason is to support our system can show on many flexible devices such as PC, mobile, tablet, etc.
                    </p>
                    <p class="justify-align">
                        Besides, the server-side supports natively python language by Dash framework integrated in Flash, Plotly frameworks. It leads to develop AI models quickly as well as integrating these models into our system.
                    </p>
                    <figure align="center">
                        <img class="round" style="height:150px" src="./resources/deployment_diagram.png"/>
                        <figcaption>Deployment Diagram</figcaption>
                    </figure>

                    <p><b>Data Store Design</b></p>
                    <p class="justify-align">
                        Only prototype purpose, we only use Pandas Library to store data files from the challenge contest.
                    </p>
                    <p class="justify-align">
                        The AI2 Core Module will preprocess data given by the organizer and convert it to a suitable data design. After that, it also runs the detection process to fill cell density.
                    </p>
                    <p class="justify-align">
                        It only keeps the items matching between sensor data and microscopy images.
                    </p>
                    <table>
                        <tr>
                            <td>
                                <figure align="center">
                                    <img class="round" style="height:250px" src="./resources/file_store.png"/>
                                    <figcaption>A2I Data Files</figcaption>
                                </figure>
                            </td>
                            <td>
                                <figure align="center">
                                    <img class="round" style="height:250px" src="./resources/data_store.png"/>
                                    <figcaption>Data Store</figcaption>
                                </figure>
                            </td>
                        </tr>
                    </table>

                    <p><b>Screen Details</b></p>

                    <p class="justify-align">
                        Finally, users can interact with our system through by DashWeb module based on Flash, Plotly frameworks. The advantage of the dash framework is flexible on many devices, as well as interacting quickly using ajax response/request to sync data between client and server.
                    </p>

                    <p class="justify-align">
                        At the data analysis screen, users can search suitable data by typing filters at the top of columns. After that, they can choose a data row for watching the corresponding microscopy image at the right of the screen. Moreover, the detection button helps users in cell density counting.
                    </p>
                    <p class="justify-align">
                        At the bottom of the screen, they can analyze data by data correlation of data fields as well as the box plot charts of every data field to visualize the data center and data spreading.
                    </p>

                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/data_analysis_screen.png"/>
                        <figcaption>Data Analsyis Screen</figcaption>
                    </figure>

                    <p class="justify-align">
                        After the data analysis phase, users can use the training screen to train the model by choosing places, dates, and the training ratio.
                        After that, the prediction screen is used to detect the cell density from the sensor data.
                    </p>

                    <table>
                        <tr>
                            <td>
                                <figure align="center">
                                    <img class="round" style="height:250px" src="./resources/training_screen.png"/>
                                    <figcaption>Training Screen</figcaption>
                                </figure>
                            </td>
                            <td>
                                <figure align="center">
                                    <img class="round" style="height:250px" src="./resources/prediction_screen.png"/>
                                    <figcaption>Prediction Screen</figcaption>
                                </figure>
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
        </table>
    </center>

    <!-- Experiments and Discussion -->
    <center>
        <h1>Experiments and Discussion</h1>
        <table align=center class="fixed">
            <tr>
                <td>
                    <p><b>Dataset Discussion</b></p>
                    <p class="justify-align">
                        In the challenge dataset, there are 122170 microscopy images and 123814 sensor data rows. We find 1648 sensor data rows for data integrity analysis without the corresponding microscopy images and four microscopy images without the corresponding data sensor rows.
                        We eliminate the rows which don't satisfy data integrity constraints and achieve 122166 data rows.
                    </p>
                    <p class="justify-align">
                        The challenge dataset collects during 21 days at at 고성, and 일해  regions.
                    </p>

                    <p class="justify-align">
                        The figure below shows the box plot chart of five water quality parameters in every region. It presents there are differences between 고성, and 일해 regions at the mean property and the data spreading property, especially temperature and salinity.
                    </p>
                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/univariate_analysis.png"/>
                        <figcaption>Univariate analysis on every attributes</figcaption>
                    </figure>

                    <p class="justify-align">
                        Next step, we analyze the correlation of water quality parameters and cell density. The darker color will point out the more correlation. The charts present the correlation among temperature, DO, pH, and salinity and the correlation between NTU and cell density. Moreover, the data correlation of 고성 region is stronger than the data correlation of 일해 region.
                    </p>
                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/data_correlation_analysis.png"/>
                        <figcaption>Data Correlation Analysis</figcaption>
                    </figure>

                    <p><b>Experiment Setup</b></p>
                    <p class="justify-align">
                        The experiment is organized into two phases: training and evaluation/testing. We choose one region to train data. Firstly, we group the training data by day and calculate the average water quality parameters and cell density. After that, we apply our model and comparison models to produce the cell density. At the testing phase, we use the k-fold cross-validation scheme or the data of the remaining region to apply the training model. To assess the model performance, we use two evaluation metrics, mean square error (MSE) and mean absolute percentage error (MAPE).
                    </p>

                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/experiment_setup.png"/>
                        <figcaption>Experiment Setup</figcaption>
                    </figure>

                    <p><b>Experiment Results</b></p>
                    <p class="justify-align">
                        The result table shows that our model in the two regions gives better results than the comparison models.
                    </p>
                    <p class="justify-align">
                        Besides, the model's performance in 고성 (Goseong) region is better than the performance in the 일해 (Ilhae) region. The reason is that the data correlations in the 고성 (Goseong) region is stronger than in the 일해 (Ilhae) region. It is to show many unobserved elements from the environment causing effects to the stable mass seed management.
                    </p>
                    <figure align="center">
                        <img class="round" style="height:250px" src="./resources/experiment_results.png"/>
                        <figcaption>Experiment Results</figcaption>
                    </figure>
                </td>
            </tr>
        </table>
    </center>

    <!-- Talk and Demo -->
    <center>
        <h1>Talk and Demo</h1>
        <table align=center class="fixed">
            <tr>
                <td>
                    <p align="center">
                        <iframe width="660" height="395" src="https://www.youtube.com/embed/T529Nq_P3qc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
                    </p>

                    <p align="center">
                        <iframe width="660" height="395" src="https://www.youtube.com/embed/Vs9v_EXVCn0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe>
                    </p>
                </td>
            </tr>
    </center>

    <!-- Citation -->
    <center>
        <table align=center class="fixed">
            <tr>
                <td>
                    <center><h1>Citation</h1></center>
                    <p class="justify-align">
                        <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
                        All material is made available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode">Creative Commons BY-NC-SA 4.0</a> license by Adobe Inc. You can <b>use, redistribute, and adapt</b> the material for <b>non-commercial purposes</b>, as long as you give appropriate credit by <b>citing our paper</b> and <b>indicating any changes</b> that you've made.
                    </p>
                </td>
            </tr>
        </table>
    </center>
</body>
</html>