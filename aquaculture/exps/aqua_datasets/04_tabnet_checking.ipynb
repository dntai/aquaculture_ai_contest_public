{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "script_dir  = os.path.normpath(os.path.abspath(\".\"))\n",
    "root_dir    = os.path.normpath(os.path.abspath(script_dir + \"/../..\"))\n",
    "if root_dir in sys.path: sys.path.remove(root_dir)\n",
    "sys.path.insert(1, root_dir)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "import glob, pandas as pd\n",
    "import tqdm, numpy as np\n",
    "from IPython import display\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_root = f'{root_dir}/data/AI_competition'\n",
    "prep_root = f'{data_root}/preprocessed'\n",
    "df_data   = pd.read_excel(f'{prep_root}/final_info.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df_data_day = df_data.groupby(['cdate', 'fplace']).mean().reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_data = df_data_day.query('fplace==\"고성\"')[[\"Temperatue\",\"DO\",\"pH\",\"salinity\",\"NTU\",\"ncells\"]].values\n",
    "test_data  = df_data_day.query('fplace==\"일해\"')[[\"Temperatue\",\"DO\",\"pH\",\"salinity\",\"NTU\",\"ncells\"]].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (21, 5), (21,)\n",
      "test:  (21, 5),  (21,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "x_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "\n",
    "y_test  = np.floor(y_test)\n",
    "y_train = np.floor(y_train)\n",
    "\n",
    "print(f'train: {x_train.shape}, {y_train.shape}')\n",
    "print(f'test:  {x_test.shape},  {y_test.shape}')\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(x_train)\n",
    "\n",
    "x_train = standard_scaler.transform(x_train)\n",
    "x_test = standard_scaler.transform(x_test)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 356 with best_epoch = 56 and best_val_0_rmse = 39.73295\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 370 with best_epoch = 70 and best_val_0_rmse = 9.3619\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 460 with best_epoch = 160 and best_val_0_rmse = 21.33043\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 409 with best_epoch = 109 and best_val_0_rmse = 12.24109\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 422 with best_epoch = 122 and best_val_0_rmse = 8.68239\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 339 with best_epoch = 39 and best_val_0_rmse = 44.1936\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 429 with best_epoch = 129 and best_val_0_rmse = 43.4636\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 369 with best_epoch = 69 and best_val_0_rmse = 9.10164\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 355 with best_epoch = 55 and best_val_0_rmse = 17.62231\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 400 with best_epoch = 100 and best_val_0_rmse = 63.13117\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "predictions_array =[]\n",
    "CV_score_array    =[]\n",
    "CV_mape_array     =[]\n",
    "CV_mse_array     =[]\n",
    "for train_index, test_index in cv.split(x_train):\n",
    "    x1_train, x1_valid = x_train[train_index], x_train[test_index]\n",
    "    y1_train, y1_valid = y_train[train_index], y_train[test_index]\n",
    "    regressor = TabNetRegressor(verbose=0,seed=42)\n",
    "    regressor.fit(X_train=x1_train, y_train=y1_train,\n",
    "              eval_set=[(x1_valid, y1_valid)],\n",
    "              patience=300, max_epochs=2000,\n",
    "              eval_metric=['rmse'])\n",
    "    CV_score_array.append(regressor.best_cost)\n",
    "    y1_pred_valid = regressor.predict(x1_valid)\n",
    "    CV_mape_array.append(mean_absolute_percentage_error(y1_valid, y1_pred_valid))\n",
    "    CV_mse_array.append(mean_squared_error(y1_valid, y1_pred_valid))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.27807645453373714, 1056.7656595174326)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CV_mape_array), np.mean(CV_mse_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (21, 5), (21,)\n",
      "test:  (21, 5),  (21,)\n",
      "\n",
      "Early stopping occurred at epoch 445 with best_epoch = 145 and best_val_0_rmse = 64.64029\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 382 with best_epoch = 82 and best_val_0_rmse = 22.22554\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 698 with best_epoch = 398 and best_val_0_rmse = 22.58709\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 396 with best_epoch = 96 and best_val_0_rmse = 116.54479\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 363 with best_epoch = 63 and best_val_0_rmse = 19.0457\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 530 with best_epoch = 230 and best_val_0_rmse = 64.87496\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 365 with best_epoch = 65 and best_val_0_rmse = 30.97446\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 363 with best_epoch = 63 and best_val_0_rmse = 40.55842\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 813 with best_epoch = 513 and best_val_0_rmse = 10.3769\n",
      "Best weights from best epoch are automatically used!\n",
      "\n",
      "Early stopping occurred at epoch 339 with best_epoch = 39 and best_val_0_rmse = 47.88605\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "x_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "\n",
    "y_test  = np.floor(y_test)\n",
    "y_train = np.floor(y_train)\n",
    "\n",
    "print(f'train: {x_train.shape}, {y_train.shape}')\n",
    "print(f'test:  {x_test.shape},  {y_test.shape}')\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(x_test)\n",
    "\n",
    "x_train = standard_scaler.transform(x_train)\n",
    "x_test = standard_scaler.transform(x_test)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "predictions_array =[]\n",
    "CV_score_array    =[]\n",
    "CV_mape_array     =[]\n",
    "CV_mse_array      =[]\n",
    "for train_index, test_index in cv.split(x_test):\n",
    "    x1_train, x1_valid = x_test[train_index], x_test[test_index]\n",
    "    y1_train, y1_valid = y_test[train_index], y_test[test_index]\n",
    "    regressor = TabNetRegressor(verbose=0,seed=42)\n",
    "    regressor.fit(X_train=x1_train, y_train=y1_train,\n",
    "              eval_set=[(x1_valid, y1_valid)],\n",
    "              patience=300, max_epochs=2000,\n",
    "              eval_metric=['rmse'])\n",
    "    CV_score_array.append(regressor.best_cost)\n",
    "    y1_pred_valid = regressor.predict(x1_valid)\n",
    "    CV_mape_array.append(mean_absolute_percentage_error(y1_valid, y1_pred_valid))\n",
    "    CV_mse_array.append(mean_squared_error(y1_valid, y1_pred_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.3970292661155891, 2834.1863348215556)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CV_mape_array), np.mean(CV_mse_array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "aqua21",
   "language": "python",
   "display_name": "aqua21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}